{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Generation\n",
    "1. For each word generate word count stream $W S_w$ by counting word frequency in doc collection for every day.\n",
    "$$wc_i = \\sum_{\\forall d\\ with\\ t_i}c(w,d), \\quad W S_w=wc_1, wc_2, ..., wc_n$$\n",
    "\n",
    "Where $c(w,d)$ is count of $w$ in the document $d$.\n",
    "\n",
    "2. Measure correlation and significance between word streams and the external non-textual time series. ? How => Identify words that are highly correlated\n",
    "\n",
    "3. Generate topic priors for significant words. Dirichlet distribution that favors topics assigning high probabilities to the identified significant words in significant topics.\n",
    "\n",
    "4. Assign prior probabilities proporational to significance of words.\n",
    "\n",
    "5. Improve topic quality.\n",
    "  - Separate positive and negative impact\n",
    "  - if one is much smaller than other, set the probability in smaller group as 0\n",
    "  \n",
    "6. Select cutoff $\\gamma$ \n",
    "\n",
    "    Given Top word $TW=(w_1,..,w_m)$ and Significance value for each word $sig(C,X,w)$, the topic prior $\\phi_w'$ can be computed by the following formula\n",
    "\n",
    "    $$\\phi_w' = \\frac{sig(C,X,w)-\\gamma}{\\sum\\nolimits_{j=1}^{m}(sig(C,X,w_j)-\\gamma)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
